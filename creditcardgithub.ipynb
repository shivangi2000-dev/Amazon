{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Full path to the CSV file\n",
    "file_path = \"/Users/shivangirai/Downloads/creditcard_2023.csv\"\n",
    "\n",
    "# Load the file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>17982.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>6531.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>2513.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>5384.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>14278.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>-0.140514</td>\n",
       "      <td>1.191138</td>\n",
       "      <td>-0.707979</td>\n",
       "      <td>0.430490</td>\n",
       "      <td>0.458973</td>\n",
       "      <td>0.611050</td>\n",
       "      <td>-0.092629</td>\n",
       "      <td>0.180811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.187739</td>\n",
       "      <td>-0.538518</td>\n",
       "      <td>-0.050465</td>\n",
       "      <td>-0.631553</td>\n",
       "      <td>-0.456480</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.066681</td>\n",
       "      <td>0.095812</td>\n",
       "      <td>6901.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.016482</td>\n",
       "      <td>-0.397181</td>\n",
       "      <td>0.497868</td>\n",
       "      <td>-0.144463</td>\n",
       "      <td>0.331022</td>\n",
       "      <td>0.629243</td>\n",
       "      <td>0.431262</td>\n",
       "      <td>-0.134007</td>\n",
       "      <td>0.796159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171137</td>\n",
       "      <td>-0.287017</td>\n",
       "      <td>-0.178197</td>\n",
       "      <td>-1.297597</td>\n",
       "      <td>1.182503</td>\n",
       "      <td>-0.604228</td>\n",
       "      <td>-0.198163</td>\n",
       "      <td>-0.087619</td>\n",
       "      <td>18954.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.051306</td>\n",
       "      <td>-0.007194</td>\n",
       "      <td>1.139941</td>\n",
       "      <td>-0.877880</td>\n",
       "      <td>0.684668</td>\n",
       "      <td>0.714326</td>\n",
       "      <td>0.892615</td>\n",
       "      <td>-0.908409</td>\n",
       "      <td>0.901938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620676</td>\n",
       "      <td>-0.920426</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>-1.091527</td>\n",
       "      <td>-0.742075</td>\n",
       "      <td>-0.104863</td>\n",
       "      <td>-1.382522</td>\n",
       "      <td>-2.748268</td>\n",
       "      <td>12298.23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.130680</td>\n",
       "      <td>-0.349547</td>\n",
       "      <td>0.425786</td>\n",
       "      <td>-0.760444</td>\n",
       "      <td>1.702777</td>\n",
       "      <td>2.324816</td>\n",
       "      <td>0.568968</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.273118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132787</td>\n",
       "      <td>-0.284700</td>\n",
       "      <td>-0.227779</td>\n",
       "      <td>2.248754</td>\n",
       "      <td>0.534846</td>\n",
       "      <td>-0.929738</td>\n",
       "      <td>-0.224385</td>\n",
       "      <td>0.243790</td>\n",
       "      <td>22052.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>-0.093507</td>\n",
       "      <td>1.117270</td>\n",
       "      <td>-0.735172</td>\n",
       "      <td>0.466111</td>\n",
       "      <td>0.332371</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>-0.136674</td>\n",
       "      <td>0.096409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203634</td>\n",
       "      <td>-0.601581</td>\n",
       "      <td>-0.145082</td>\n",
       "      <td>-0.654783</td>\n",
       "      <td>-0.196621</td>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.057119</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>210.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1   1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2   2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3   3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4   4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "5   5  0.025302 -0.140514  1.191138 -0.707979  0.430490  0.458973  0.611050   \n",
       "6   6  1.016482 -0.397181  0.497868 -0.144463  0.331022  0.629243  0.431262   \n",
       "7   7 -0.051306 -0.007194  1.139941 -0.877880  0.684668  0.714326  0.892615   \n",
       "8   8 -0.130680 -0.349547  0.425786 -0.760444  1.702777  2.324816  0.568968   \n",
       "9   9  0.058419 -0.093507  1.117270 -0.735172  0.466111  0.332371  0.683425   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0 -0.130006  0.727159  ... -0.110552  0.217606 -0.134794  0.165959  0.126280   \n",
       "1 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469 -0.577395  0.190090   \n",
       "2 -0.095576 -0.261297  ... -0.005020  0.702906  0.945045 -1.154666 -0.605564   \n",
       "3 -0.065130 -0.205698  ... -0.146927 -0.038212 -0.214048 -1.893131  1.003963   \n",
       "4 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666  0.312561 -0.414116   \n",
       "5 -0.092629  0.180811  ... -0.187739 -0.538518 -0.050465 -0.631553 -0.456480   \n",
       "6 -0.134007  0.796159  ... -0.171137 -0.287017 -0.178197 -1.297597  1.182503   \n",
       "7 -0.908409  0.901938  ...  0.620676 -0.920426  0.034660 -1.091527 -0.742075   \n",
       "8  0.049100  0.273118  ... -0.132787 -0.284700 -0.227779  2.248754  0.534846   \n",
       "9 -0.136674  0.096409  ... -0.203634 -0.601581 -0.145082 -0.654783 -0.196621   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
       "1  0.296503 -0.248052 -0.064512   6531.37      0  \n",
       "2 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
       "3 -0.515950 -0.165316  0.048424   5384.44      0  \n",
       "4  1.071126  0.023712  0.419117  14278.97      0  \n",
       "5  0.252670  0.066681  0.095812   6901.49      0  \n",
       "6 -0.604228 -0.198163 -0.087619  18954.45      0  \n",
       "7 -0.104863 -1.382522 -2.748268  12298.23      0  \n",
       "8 -0.929738 -0.224385  0.243790  22052.90      0  \n",
       "9  0.226818  0.057119  0.100629    210.35      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568630, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates.sum())  # Number of duplicate rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates.sum())  # Number of duplicate rows\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after removing outliers:\n",
      "            id        V1        V2        V3        V4        V5        V6  \\\n",
      "1            1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605   \n",
      "4            4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549   \n",
      "5            5  0.025302 -0.140514  1.191138 -0.707979  0.430490  0.458973   \n",
      "6            6  1.016482 -0.397181  0.497868 -0.144463  0.331022  0.629243   \n",
      "9            9  0.058419 -0.093507  1.117270 -0.735172  0.466111  0.332371   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "568611  568611 -0.615271  0.186434 -0.030647  0.214008 -0.253675  0.349331   \n",
      "568612  568612  0.941162 -0.281207  0.502989 -0.052894  0.312189  0.337272   \n",
      "568616  568616 -0.120366  0.166819 -0.270633 -0.353998  0.468713 -0.321819   \n",
      "568627  568627 -0.311997 -0.004095  0.137526 -0.035893 -0.042291  0.121098   \n",
      "568628  568628  0.636871 -0.516970 -0.300889 -0.144480  0.131042 -0.294148   \n",
      "\n",
      "              V7        V8        V9  ...       V21       V22       V23  \\\n",
      "1       0.406466 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469   \n",
      "4       0.658849 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666   \n",
      "5       0.611050 -0.092629  0.180811  ... -0.187739 -0.538518 -0.050465   \n",
      "6       0.431262 -0.134007  0.796159  ... -0.171137 -0.287017 -0.178197   \n",
      "9       0.683425 -0.136674  0.096409  ... -0.203634 -0.601581 -0.145082   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "568611  0.334228 -0.129740  0.016706  ... -0.073235 -0.867431  0.311927   \n",
      "568612  0.463182 -0.137530  0.200863  ... -0.144141 -0.223873 -0.026104   \n",
      "568616  0.175881 -0.017534 -0.377283  ...  0.066853  0.063864 -0.359510   \n",
      "568627 -0.070958 -0.019997 -0.122048  ...  0.140788  0.536523 -0.211100   \n",
      "568628  0.580568 -0.207723  0.893527  ... -0.060381 -0.195609 -0.175488   \n",
      "\n",
      "             V24       V25       V26       V27       V28    Amount  Class  \n",
      "1      -0.577395  0.190090  0.296503 -0.248052 -0.064512   6531.37      0  \n",
      "4       0.312561 -0.414116  1.071126  0.023712  0.419117  14278.97      0  \n",
      "5      -0.631553 -0.456480  0.252670  0.066681  0.095812   6901.49      0  \n",
      "6      -1.297597  1.182503 -0.604228 -0.198163 -0.087619  18954.45      0  \n",
      "9      -0.654783 -0.196621  0.226818  0.057119  0.100629    210.35      0  \n",
      "...          ...       ...       ...       ...       ...       ...    ...  \n",
      "568611 -0.056118 -0.428920  0.174252 -0.671992 -0.427411   3114.55      1  \n",
      "568612  0.172613  0.601470  0.406978 -0.240575 -0.044876  13057.49      1  \n",
      "568616 -0.119500  0.504786  0.431325  0.170375  0.356759  16790.09      1  \n",
      "568627 -0.448909  0.540073 -0.755836 -0.487540 -0.268741  23572.85      1  \n",
      "568628 -0.554643 -0.099669 -1.434931 -0.159269 -0.076251  10160.83      1  \n",
      "\n",
      "[245934 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select numerical columns to check for outliers\n",
    "columns_to_check = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Detect and remove outliers for each column\n",
    "for col in columns_to_check:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter out rows where the column has outliers\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "print(\"Dataset after removing outliers:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rows before and after removing the outliers remain the sme  which means there were no  outliers in the dataset \n",
    "# the data set is normally distribtued   ,with no cleaning , preproocessing needed ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#corelation  heatmap \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      6\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m df[numeric_columns]\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[1;32m      7\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(correlation_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Select only numerical columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "#corelation  heatmap \n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from the image  class and id have the strong corelation with value of 0.8 \n",
    "# from the code , we  get the same result . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongly correlated column pairs (|correlation| > 0.8):\n",
      "Class and id with correlation: 0.84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `df` is your dataset\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Define a threshold for strong correlation\n",
    "threshold = 0.8\n",
    "\n",
    "# Find pairs of strongly correlated columns\n",
    "strong_pairs = []\n",
    "\n",
    "# Iterate over the matrix\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            col1 = correlation_matrix.columns[i]\n",
    "            col2 = correlation_matrix.columns[j]\n",
    "            strong_pairs.append((col1, col2, correlation_matrix.iloc[i, j]))\n",
    "\n",
    "# Display strongly correlated column pairs\n",
    "print(\"Strongly correlated column pairs (|correlation| > 0.8):\")\n",
    "for pair in strong_pairs:\n",
    "    print(f\"{pair[0]} and {pair[1]} with correlation: {pair[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnecessary columns which are not useful for the model prediction \n",
    "# Drop the 'id' column (not useful for predictions)\n",
    "df = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245934, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "Class\n",
      "0    0.736222\n",
      "1    0.263778\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(df['Class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    181062\n",
      "1     64872\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if there is class imbalance \n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use smote- SMOTE is designed for classification tasks where the target variable has categorical classes (e.g., 0 and 1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE:\n",
      "Class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Handle Class Imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Check class distribution after resampling\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(y_resampled).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "Confusion Matrix:\n",
      "[[52675  1644]\n",
      " [ 2647 51672]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     54319\n",
      "           1       0.97      0.95      0.96     54319\n",
      "\n",
      "    accuracy                           0.96    108638\n",
      "   macro avg       0.96      0.96      0.96    108638\n",
      "weighted avg       0.96      0.96      0.96    108638\n",
      "\n",
      "AUC-ROC Score:\n",
      "0.9932178759917876\n",
      "\n",
      "Random Forest Evaluation:\n",
      "Confusion Matrix:\n",
      "[[54313     6]\n",
      " [    4 54315]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     54319\n",
      "           1       1.00      1.00      1.00     54319\n",
      "\n",
      "    accuracy                           1.00    108638\n",
      "   macro avg       1.00      1.00      1.00    108638\n",
      "weighted avg       1.00      1.00      1.00    108638\n",
      "\n",
      "AUC-ROC Score:\n",
      "0.9999999525512798\n"
     ]
    }
   ],
   "source": [
    "#applying ml models\n",
    "# Train Logistic Regression Model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"AUC-ROC Score:\")\n",
    "    print(roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "evaluate_model(lr_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "evaluate_model(rf_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m rf_y_pred \u001b[38;5;241m=\u001b[39m random_forest_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate and display metrics for Logistic Regression\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m logistic_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, logistic_y_pred)\n\u001b[1;32m     13\u001b[0m logistic_conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, logistic_y_pred)\n\u001b[1;32m     14\u001b[0m logistic_classification_report \u001b[38;5;241m=\u001b[39m classification_report(y_test, logistic_y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "logistic_y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Random Forest Model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "rf_y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calculate and display metrics for Logistic Regression\n",
    "logistic_accuracy = accuracy_score(y_test, logistic_y_pred)\n",
    "logistic_conf_matrix = confusion_matrix(y_test, logistic_y_pred)\n",
    "logistic_classification_report = classification_report(y_test, logistic_y_pred)\n",
    "logistic_auc_roc = roc_auc_score(y_test, logistic_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(f\"Accuracy: {logistic_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(logistic_conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(logistic_classification_report)\n",
    "print(f\"AUC-ROC Score: {logistic_auc_roc}\")\n",
    "\n",
    "# Calculate and display metrics for Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "rf_classification_report = classification_report(y_test, rf_y_pred)\n",
    "rf_auc_roc = roc_auc_score(y_test, random_forest_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "print(f\"Accuracy: {rf_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(rf_conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(rf_classification_report)\n",
    "print(f\"AUC-ROC Score: {rf_auc_roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp and sigmoid function is nto typically relevant  when the data is cateogorical or numerical \n",
    "# in most real life datasets/banks neural network with a siggmoid activation is used for binary classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the Neural Network\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid activation for binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419us/step - accuracy: 0.9789 - loss: 0.0537 - val_accuracy: 0.9986 - val_loss: 0.0047\n",
      "Epoch 2/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 410us/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9994 - val_loss: 0.0023\n",
      "Epoch 3/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404us/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9985 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399us/step - accuracy: 0.9994 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0021\n",
      "Epoch 5/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399us/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9997 - val_loss: 0.0013\n",
      "Epoch 6/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 413us/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9998 - val_loss: 0.0017\n",
      "Epoch 7/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402us/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9997 - val_loss: 0.0012\n",
      "Epoch 8/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406us/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9991 - val_loss: 0.0038\n",
      "Epoch 9/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400us/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9997 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402us/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9997 - val_loss: 0.0011\n",
      "Epoch 11/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399us/step - accuracy: 0.9998 - loss: 8.0996e-04 - val_accuracy: 0.9999 - val_loss: 8.1476e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400us/step - accuracy: 0.9998 - loss: 8.1755e-04 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
      "Epoch 13/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400us/step - accuracy: 0.9998 - loss: 9.1272e-04 - val_accuracy: 0.9997 - val_loss: 0.0015\n",
      "Epoch 14/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406us/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9998 - val_loss: 8.1235e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 403us/step - accuracy: 0.9999 - loss: 5.7259e-04 - val_accuracy: 0.9998 - val_loss: 8.4870e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 409us/step - accuracy: 0.9998 - loss: 7.0340e-04 - val_accuracy: 0.9999 - val_loss: 8.5079e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408us/step - accuracy: 0.9998 - loss: 8.2713e-04 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
      "Epoch 18/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401us/step - accuracy: 0.9998 - loss: 6.0560e-04 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
      "Epoch 19/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 402us/step - accuracy: 0.9999 - loss: 6.0048e-04 - val_accuracy: 0.9998 - val_loss: 0.0011\n",
      "Epoch 20/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406us/step - accuracy: 0.9999 - loss: 5.2102e-04 - val_accuracy: 0.9997 - val_loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 405us/step - accuracy: 0.9999 - loss: 5.1416e-04 - val_accuracy: 0.9999 - val_loss: 8.1176e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400us/step - accuracy: 0.9999 - loss: 4.6522e-04 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
      "Epoch 3/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399us/step - accuracy: 0.9999 - loss: 5.2005e-04 - val_accuracy: 0.9998 - val_loss: 0.0015\n",
      "Epoch 4/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 791us/step - accuracy: 0.9999 - loss: 3.1581e-04 - val_accuracy: 0.9998 - val_loss: 0.0015\n",
      "Epoch 5/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 924us/step - accuracy: 0.9999 - loss: 5.2526e-04 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
      "Epoch 6/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 896us/step - accuracy: 0.9999 - loss: 3.9738e-04 - val_accuracy: 0.9997 - val_loss: 0.0020\n",
      "Epoch 7/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 900us/step - accuracy: 0.9999 - loss: 3.8117e-04 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
      "Epoch 8/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 898us/step - accuracy: 0.9999 - loss: 3.4719e-04 - val_accuracy: 0.9997 - val_loss: 0.0020\n",
      "Epoch 9/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 890us/step - accuracy: 0.9999 - loss: 6.3294e-04 - val_accuracy: 0.9999 - val_loss: 0.0011\n",
      "Epoch 10/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 918us/step - accuracy: 0.9999 - loss: 3.0252e-04 - val_accuracy: 0.9997 - val_loss: 0.0021\n",
      "Epoch 11/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 927us/step - accuracy: 0.9998 - loss: 9.0066e-04 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
      "Epoch 12/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 913us/step - accuracy: 0.9999 - loss: 2.2845e-04 - val_accuracy: 0.9998 - val_loss: 0.0017\n",
      "Epoch 13/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 959us/step - accuracy: 0.9999 - loss: 5.0535e-04 - val_accuracy: 0.9998 - val_loss: 0.0016\n",
      "Epoch 14/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 895us/step - accuracy: 0.9999 - loss: 3.7795e-04 - val_accuracy: 0.9998 - val_loss: 0.0017\n",
      "Epoch 15/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 938us/step - accuracy: 0.9998 - loss: 8.0952e-04 - val_accuracy: 0.9999 - val_loss: 0.0018\n",
      "Epoch 16/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 942us/step - accuracy: 0.9999 - loss: 4.9014e-04 - val_accuracy: 0.9998 - val_loss: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 920us/step - accuracy: 0.9999 - loss: 6.0966e-04 - val_accuracy: 0.9998 - val_loss: 0.0017\n",
      "Epoch 18/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.6811e-04 - val_accuracy: 0.9997 - val_loss: 0.0021\n",
      "Epoch 19/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 992us/step - accuracy: 1.0000 - loss: 2.7032e-04 - val_accuracy: 0.9996 - val_loss: 0.0031\n",
      "Epoch 20/20\n",
      "\u001b[1m7922/7922\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 922us/step - accuracy: 0.9999 - loss: 5.6777e-04 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
      "\u001b[1m3395/3395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288us/step\n",
      "Confusion Matrix:\n",
      "[[54302    17]\n",
      " [    0 54319]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     54319\n",
      "           1       1.00      1.00      1.00     54319\n",
      "\n",
      "    accuracy                           1.00    108638\n",
      "   macro avg       1.00      1.00      1.00    108638\n",
      "weighted avg       1.00      1.00      1.00    108638\n",
      "\n",
      "\n",
      "AUC-ROC Score:\n",
      "0.9999748903067013\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_proba = model.predict(X_test).ravel()\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAUC-ROC Score:\")\n",
    "print(roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people predicted to default the loan: 54336\n"
     ]
    }
   ],
   "source": [
    "# Number of people predicted to default the loan\n",
    "num_defaults_predicted = np.sum(y_pred)\n",
    "print(f\"Number of people predicted to default the loan: {num_defaults_predicted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of people who actually defaulted:\n",
      "[[-0.9017357   2.09633824 -1.62956879 ...  1.81602589  1.73059379\n",
      "  -0.37512192]\n",
      " [-0.31418966  1.01995772 -0.7482041  ...  2.5603955   2.46570905\n",
      "   0.72508907]\n",
      " [-0.49626944  0.76306418  0.58407262 ... -1.68186837 -2.48473857\n",
      "   1.28269432]\n",
      " ...\n",
      " [-0.70939114  1.09435523 -1.47245634 ...  0.61733484 -0.64453649\n",
      "  -0.72963738]\n",
      " [-0.27874117  0.73323769 -0.87454051 ...  2.57679198  2.29167165\n",
      "   0.82007545]\n",
      " [-0.82870868  1.15105142 -0.78987442 ...  2.73887101  2.08568559\n",
      "   0.68634565]]\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of people who actually defaulted\n",
    "defaulted_indices = np.where(y_test == 1)[0]\n",
    "\n",
    "# Extract the corresponding rows from X_test (or the original dataset if available)\n",
    "defaulted_people = X_test[defaulted_indices]\n",
    "\n",
    "print(f\"Data of people who actually defaulted:\")\n",
    "print(defaulted_people)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming X_test is originally a DataFrame and has column names\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m defaulted_people_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(defaulted_people, columns\u001b[38;5;241m=\u001b[39mX_test\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Display the DataFrame\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData of people who actually defaulted:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X_test is originally a DataFrame and has column names\n",
    "defaulted_people_df = pd.DataFrame(defaulted_people, columns=X_test.columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Data of people who actually defaulted:\")\n",
    "print(defaulted_people_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of people who actually defaulted:\n",
      "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "0      -0.901736   2.096338  -1.629569   1.524466  -0.619094  -1.249584   \n",
      "1      -0.314190   1.019958  -0.748204   1.656438  -1.079957  -0.370960   \n",
      "2      -0.496269   0.763064   0.584073   1.100146   2.133497   1.218843   \n",
      "3       0.558697   0.094483  -0.121275   0.227360   0.331024  -0.121455   \n",
      "4      -1.007599   1.473444  -1.821929   1.247968  -2.285935  -0.280188   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "54314  -0.405782  -0.633361  -0.726678  -0.078958   2.118533  -0.666908   \n",
      "54315  -0.658094   0.416170   0.455085   0.563390   1.078105  -0.330626   \n",
      "54316  -0.709391   1.094355  -1.472456   1.239427  -0.963452  -0.266124   \n",
      "54317  -0.278741   0.733238  -0.874541   1.056962  -1.052403  -0.019213   \n",
      "54318  -0.828709   1.151051  -0.789874   1.636503  -1.405145   0.351638   \n",
      "\n",
      "       Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_20  \\\n",
      "0      -2.289440   2.614479  -0.998818   -2.484916  ...    1.281250   \n",
      "1      -1.675038   0.793223  -1.140858   -1.389893  ...    1.414791   \n",
      "2       1.584960  -0.673577  -1.183533    1.683953  ...   -0.535855   \n",
      "3       0.382132  -0.568078   0.000625    0.061747  ...   -0.295187   \n",
      "4       0.397551   1.149728   0.015194   -1.910272  ...   -1.335533   \n",
      "...          ...        ...        ...         ...  ...         ...   \n",
      "54314   0.130273  -1.654273   0.869698    0.282138  ...   -2.875058   \n",
      "54315   0.964137  -0.821156  -0.362027    0.309019  ...    0.104768   \n",
      "54316  -1.385008   1.363983  -1.106466   -1.538413  ...    1.815927   \n",
      "54317  -1.856736   1.249746  -0.861010   -1.434380  ...    1.294587   \n",
      "54318  -2.215424   2.540752  -1.636172   -1.255880  ...    1.309277   \n",
      "\n",
      "       Feature_21  Feature_22  Feature_23  Feature_24  Feature_25  Feature_26  \\\n",
      "0        1.078252   -1.066336   -0.303727   -0.950867    0.484537    0.567385   \n",
      "1        0.858340   -0.220317   -0.738715    0.603344    1.911067    0.327352   \n",
      "2        0.508064    1.250608   -0.915796    1.663606   -0.365779   -0.106555   \n",
      "3       -0.473008   -0.311029   -0.293671   -0.259739    1.233980    0.057951   \n",
      "4        0.692806   -0.015314    0.760175   -0.650034   -2.353536   -1.562010   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "54314    2.396175    2.285489    0.365133    0.386618   -0.881154   -0.484802   \n",
      "54315    0.384340    1.087187   -0.302474    1.315329   -1.028135    1.551993   \n",
      "54316    2.370719    2.013183    1.473712    0.530981   -0.904914   -0.104165   \n",
      "54317    1.419138    0.306737   -1.305060   -0.947276    1.933828   -0.186462   \n",
      "54318    2.108280    0.664456   -0.314158   -0.597008   -0.202821    0.615704   \n",
      "\n",
      "       Feature_27  Feature_28  Feature_29  \n",
      "0        1.816026    1.730594   -0.375122  \n",
      "1        2.560395    2.465709    0.725089  \n",
      "2       -1.681868   -2.484739    1.282694  \n",
      "3       -0.388339   -0.125018    0.406970  \n",
      "4        0.283706   -0.956251   -1.200084  \n",
      "...           ...         ...         ...  \n",
      "54314    0.756273   -0.045098   -0.172639  \n",
      "54315   -1.280220   -0.628222   -0.895254  \n",
      "54316    0.617335   -0.644536   -0.729637  \n",
      "54317    2.576792    2.291672    0.820075  \n",
      "54318    2.738871    2.085686    0.686346  \n",
      "\n",
      "[54319 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# If X_test doesn't have column names, add placeholders\n",
    "feature_names = [f\"Feature_{i+1}\" for i in range(defaulted_people.shape[1])]\n",
    "\n",
    "# Convert to DataFrame\n",
    "defaulted_people_df = pd.DataFrame(defaulted_people, columns=feature_names)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Data of people who actually defaulted:\")\n",
    "print(defaulted_people_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of people who actually defaulted:\n",
      "             V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0     -0.901736  2.096338 -1.629569  1.524466 -0.619094 -1.249584 -2.289440   \n",
      "1     -0.314190  1.019958 -0.748204  1.656438 -1.079957 -0.370960 -1.675038   \n",
      "2     -0.496269  0.763064  0.584073  1.100146  2.133497  1.218843  1.584960   \n",
      "3      0.558697  0.094483 -0.121275  0.227360  0.331024 -0.121455  0.382132   \n",
      "4     -1.007599  1.473444 -1.821929  1.247968 -2.285935 -0.280188  0.397551   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "54314 -0.405782 -0.633361 -0.726678 -0.078958  2.118533 -0.666908  0.130273   \n",
      "54315 -0.658094  0.416170  0.455085  0.563390  1.078105 -0.330626  0.964137   \n",
      "54316 -0.709391  1.094355 -1.472456  1.239427 -0.963452 -0.266124 -1.385008   \n",
      "54317 -0.278741  0.733238 -0.874541  1.056962 -1.052403 -0.019213 -1.856736   \n",
      "54318 -0.828709  1.151051 -0.789874  1.636503 -1.405145  0.351638 -2.215424   \n",
      "\n",
      "             V8        V9       V10  ...       V20       V21       V22  \\\n",
      "0      2.614479 -0.998818 -2.484916  ...  1.281250  1.078252 -1.066336   \n",
      "1      0.793223 -1.140858 -1.389893  ...  1.414791  0.858340 -0.220317   \n",
      "2     -0.673577 -1.183533  1.683953  ... -0.535855  0.508064  1.250608   \n",
      "3     -0.568078  0.000625  0.061747  ... -0.295187 -0.473008 -0.311029   \n",
      "4      1.149728  0.015194 -1.910272  ... -1.335533  0.692806 -0.015314   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "54314 -1.654273  0.869698  0.282138  ... -2.875058  2.396175  2.285489   \n",
      "54315 -0.821156 -0.362027  0.309019  ...  0.104768  0.384340  1.087187   \n",
      "54316  1.363983 -1.106466 -1.538413  ...  1.815927  2.370719  2.013183   \n",
      "54317  1.249746 -0.861010 -1.434380  ...  1.294587  1.419138  0.306737   \n",
      "54318  2.540752 -1.636172 -1.255880  ...  1.309277  2.108280  0.664456   \n",
      "\n",
      "            V23       V24       V25       V26       V27       V28    Amount  \n",
      "0     -0.303727 -0.950867  0.484537  0.567385  1.816026  1.730594 -0.375122  \n",
      "1     -0.738715  0.603344  1.911067  0.327352  2.560395  2.465709  0.725089  \n",
      "2     -0.915796  1.663606 -0.365779 -0.106555 -1.681868 -2.484739  1.282694  \n",
      "3     -0.293671 -0.259739  1.233980  0.057951 -0.388339 -0.125018  0.406970  \n",
      "4      0.760175 -0.650034 -2.353536 -1.562010  0.283706 -0.956251 -1.200084  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "54314  0.365133  0.386618 -0.881154 -0.484802  0.756273 -0.045098 -0.172639  \n",
      "54315 -0.302474  1.315329 -1.028135  1.551993 -1.280220 -0.628222 -0.895254  \n",
      "54316  1.473712  0.530981 -0.904914 -0.104165  0.617335 -0.644536 -0.729637  \n",
      "54317 -1.305060 -0.947276  1.933828 -0.186462  2.576792  2.291672  0.820075  \n",
      "54318 -0.314158 -0.597008 -0.202821  0.615704  2.738871  2.085686  0.686346  \n",
      "\n",
      "[54319 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the original dataset is called `X` and it is a DataFrame\n",
    "# Replace X with your actual original DataFrame variable name\n",
    "\n",
    "# Get the column names from the original dataset\n",
    "column_names = X.columns\n",
    "\n",
    "# Convert the extracted data of defaulted people to a DataFrame\n",
    "defaulted_df = pd.DataFrame(defaulted_people, columns=column_names)\n",
    "\n",
    "# Save to CSV or display the DataFrame\n",
    "defaulted_df.to_csv(\"defaulted_people.csv\", index=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Data of people who actually defaulted:\")\n",
    "print(defaulted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of people predicted to default:\n",
      "[[-0.9017357   2.09633824 -1.62956879 ...  1.81602589  1.73059379\n",
      "  -0.37512192]\n",
      " [-0.31418966  1.01995772 -0.7482041  ...  2.5603955   2.46570905\n",
      "   0.72508907]\n",
      " [-0.49626944  0.76306418  0.58407262 ... -1.68186837 -2.48473857\n",
      "   1.28269432]\n",
      " ...\n",
      " [-0.70939114  1.09435523 -1.47245634 ...  0.61733484 -0.64453649\n",
      "  -0.72963738]\n",
      " [-0.27874117  0.73323769 -0.87454051 ...  2.57679198  2.29167165\n",
      "   0.82007545]\n",
      " [-0.82870868  1.15105142 -0.78987442 ...  2.73887101  2.08568559\n",
      "   0.68634565]]\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of people predicted to default\n",
    "predicted_default_indices = np.where(y_pred == 1)[0]\n",
    "\n",
    "# Extract the corresponding rows from X_test (or the original dataset if available)\n",
    "predicted_defaulted_people = X_test[predicted_default_indices]\n",
    "\n",
    "print(f\"Data of people predicted to default:\")\n",
    "print(predicted_defaulted_people)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert extracted data to DataFrame (assume X_test is a DataFrame)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m defaulted_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(defaulted_people, columns\u001b[38;5;241m=\u001b[39mX_test\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[1;32m      7\u001b[0m defaulted_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefaulted_people.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert extracted data to DataFrame (assume X_test is a DataFrame)\n",
    "defaulted_df = pd.DataFrame(defaulted_people, columns=X_test.columns)\n",
    "\n",
    "# Save to CSV\n",
    "defaulted_df.to_csv(\"defaulted_people.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
